{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cb2296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "k=cohen_kappa_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "96c682f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324a81d4",
   "metadata": {},
   "source": [
    "# checking which excel files has more positive values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "c047c364",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_lockdowns=pd.read_csv(\"/Users/abhishekshastry/Documents/Illinois_tech/Subjects/Fall-2021/NLP/Assignments/Assignment2/Solution/Primary_dataset/nyt_topic_lockdowns_final_primary_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "b067d300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_lockdowns=0\n",
    "# for x in df_topic_lockdowns.final_label.values:\n",
    "#        if x==True:\n",
    "#         count_lockdowns=count_lockdowns+1\n",
    "# print('Positive lockdown values', count_lockdowns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "4b6a8b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    711\n",
      "True     102\n",
      "Name: final_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_topic_lockdowns['final_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "2c739d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_masking_distancing=pd.read_csv(\"/Users/abhishekshastry/Documents/Illinois_tech/Subjects/Fall-2021/NLP/Assignments/Assignment2/Solution/Primary_dataset/nyt_topic_masking_and_distancing_final_primary_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "c54c1fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_masking=0\n",
    "# for x in df_topic_masking_distancing.final_label.values:\n",
    "#        if x==True:\n",
    "#         count_masking=count_masking+1\n",
    "# print('Positive masking_distancing values', count_masking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "d4898173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    586\n",
      "True     227\n",
      "Name: final_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_topic_masking_distancing['final_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "f918040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_vaccination=pd.read_csv(\"/Users/abhishekshastry/Documents/Illinois_tech/Subjects/Fall-2021/NLP/Assignments/Assignment2/Solution/Primary_dataset/nyt_topic_vaccination_final_primary_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "a17614ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_vaccination=0\n",
    "# for x in df_topic_vaccination.final_label.values:\n",
    "#        if x==True:\n",
    "#         count_vaccination=count_vaccination+1\n",
    "# print('Positive count_vaccination values', count_vaccination)\n",
    "# print(df_topic_vaccination['final_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "1eeb9950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     496\n",
      "False    317\n",
      "Name: final_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_topic_vaccination['final_label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873c21aa",
   "metadata": {},
   "source": [
    "# I will be considering vaccination as a topic as it has most positive values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb71bba",
   "metadata": {},
   "source": [
    "# Primary raw data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "20730ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-485-e9bff2b00ed9>:1: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df_topic_vaccination.data=df_topic_vaccination['text']\n",
      "<ipython-input-485-e9bff2b00ed9>:2: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df_topic_vaccination.target=df_topic_vaccination['final_label']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(813,)"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_vaccination.data=df_topic_vaccination['text']\n",
    "df_topic_vaccination.target=df_topic_vaccination['final_label']\n",
    "df_topic_vaccination.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "33ec7236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(813,)"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_vaccination['final_label'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b525d626",
   "metadata": {},
   "source": [
    "# using gausian naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "6ebec67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(813, 6274)"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "df_X_train_primary = count_vect.fit_transform(df_topic_vaccination.data)\n",
    "df_X_train_primary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "6ac2c6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(813, 6274)"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "df_X_train_tfidf = tfidf_transformer.fit_transform(df_X_train_primary).toarray()\n",
    "df_X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "6f035335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6762295081967213\n",
      "0.7641791044776118\n",
      "0.6918918918918919\n"
     ]
    }
   ],
   "source": [
    "X_train_primary, X_test_primary, y_train_primary, y_test_primary = train_test_split(df_X_train_tfidf, df_topic_vaccination.target, test_size = 0.3, random_state = 0)\n",
    "model = GaussianNB()\n",
    "gausian_model_primary=model.fit(X_train_primary,y_train_primary)\n",
    "y_pred_primary_gausian = gausian_model_primary.predict(X_test_primary)\n",
    "print(accuracy_score(y_test_primary, y_pred_primary_gausian))\n",
    "print(f1_score(y_test_primary, y_pred_primary_gausian))\n",
    "print(precision_score(y_test_primary,y_pred_primary_gausian))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "7ce7efcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        TRUE       0.63      0.39      0.48        94\n",
      "       FALSE       0.69      0.85      0.76       150\n",
      "\n",
      "    accuracy                           0.68       244\n",
      "   macro avg       0.66      0.62      0.62       244\n",
      "weighted avg       0.67      0.68      0.66       244\n",
      "\n",
      "[[ 37  57]\n",
      " [ 22 128]]\n"
     ]
    }
   ],
   "source": [
    "df_topic_vaccination_target_names=[\"TRUE\",\"FALSE\"]\n",
    "print(metrics.classification_report(y_test_primary, y_pred_primary_gausian,target_names=df_topic_vaccination_target_names))\n",
    "cm = metrics.confusion_matrix(y_test_primary,y_pred_primary_gausian)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e63d893",
   "metadata": {},
   "source": [
    "# using gausian bayes on set of primary baseline model accuarcy is 68%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59878429",
   "metadata": {},
   "source": [
    "# using Multinomial naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "8a33e116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6147540983606558\n",
      "0.7614213197969544\n",
      "0.6147540983606558\n"
     ]
    }
   ],
   "source": [
    "nb_model_primary = MultinomialNB(alpha=1.0).fit(X_train_primary, y_train_primary)\n",
    "y_pred_Mnb_primary = nb_model_primary.predict(X_test_primary)\n",
    "print(accuracy_score(y_test_primary, y_pred_Mnb_primary))\n",
    "print(f1_score(y_test_primary, y_pred_Mnb_primary))\n",
    "print(precision_score(y_test_primary, y_pred_Mnb_primary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "4d6957a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        TRUE       0.00      0.00      0.00        94\n",
      "       FALSE       0.61      1.00      0.76       150\n",
      "\n",
      "    accuracy                           0.61       244\n",
      "   macro avg       0.31      0.50      0.38       244\n",
      "weighted avg       0.38      0.61      0.47       244\n",
      "\n",
      "[[  0  94]\n",
      " [  0 150]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishekshastry/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/abhishekshastry/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/abhishekshastry/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "df_topic_vaccination_target_names=[\"TRUE\",\"FALSE\"]\n",
    "print(metrics.classification_report(y_test_primary, y_pred_Mnb_primary,target_names=df_topic_vaccination_target_names))\n",
    "cm = metrics.confusion_matrix(y_test_primary,y_pred_Mnb_primary)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adfdd0b",
   "metadata": {},
   "source": [
    "# using multinomial bayes on set of primary baseline model accuarcy is 61%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22c1983",
   "metadata": {},
   "source": [
    "# using random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "32672c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8360655737704918\n",
      "0.8780487804878049\n",
      "0.8089887640449438\n"
     ]
    }
   ],
   "source": [
    "classifier_rf = RandomForestClassifier(n_estimators=100)\n",
    "classifier_rf.fit(X_train_primary, y_train_primary)\n",
    "y_pred_rf_primary=classifier_rf.predict(X_test_primary)\n",
    "print(accuracy_score(y_test_primary,y_pred_rf_primary))\n",
    "print(f1_score(y_test_primary, y_pred_rf_primary))\n",
    "print(precision_score(y_test_primary,y_pred_rf_primary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "c08470b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        TRUE       0.91      0.64      0.75        94\n",
      "       FALSE       0.81      0.96      0.88       150\n",
      "\n",
      "    accuracy                           0.84       244\n",
      "   macro avg       0.86      0.80      0.81       244\n",
      "weighted avg       0.85      0.84      0.83       244\n",
      "\n",
      "[[ 60  34]\n",
      " [  6 144]]\n"
     ]
    }
   ],
   "source": [
    "df_topic_vaccination_target_names=[\"TRUE\",\"FALSE\"]\n",
    "print(metrics.classification_report(y_test_primary, y_pred_rf_primary,target_names=df_topic_vaccination_target_names))\n",
    "cm = metrics.confusion_matrix(y_test_primary,y_pred_rf_primary)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246d5e6c",
   "metadata": {},
   "source": [
    "# using random forest on set of primary baseline model accuarcy is 84%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43580ce4",
   "metadata": {},
   "source": [
    "# Testing on secondary raw data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "82b9385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_vaccination_secondary=pd.read_csv(\"/Users/abhishekshastry/Documents/Illinois_tech/Subjects/Fall-2021/NLP/Assignments/Assignment2/Solution/secondary_dataset/change_org_topic_vaccination_final_secondary_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "adc02d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-540-47f7843e63ea>:1: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df_topic_vaccination_secondary.data=df_topic_vaccination_secondary['text']\n",
      "<ipython-input-540-47f7843e63ea>:2: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df_topic_vaccination_secondary.target=df_topic_vaccination_secondary['final_label']\n"
     ]
    }
   ],
   "source": [
    "df_topic_vaccination_secondary.data=df_topic_vaccination_secondary['text']\n",
    "df_topic_vaccination_secondary.target=df_topic_vaccination_secondary['final_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccd398f",
   "metadata": {},
   "source": [
    "# Using the already fitted Multinomial classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "848b20d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 6274)\n",
      "(1500, 6274)\n",
      "0.037333333333333336\n",
      "0.03604806408544726\n",
      "0.018354860639021073\n"
     ]
    }
   ],
   "source": [
    "df_X_test_secondary = count_vect.transform(df_topic_vaccination_secondary['text'])\n",
    "print(df_X_test_secondary.shape)\n",
    "df_X__test_tfidf_secondary = tfidf_transformer.transform(df_X_count_secondary)\n",
    "print(df_X__test_tfidf_secondary.shape)\n",
    "# using trained nb classifer\n",
    "y_pred_Mnb_secondary= nb_model_primary.predict(df_X__test_tfidf_secondary)\n",
    "print(accuracy_score(df_topic_vaccination_secondary.target, y_pred_Mnb_secondary))\n",
    "print(f1_score(df_topic_vaccination_secondary.target, y_pred_Mnb_secondary))\n",
    "print(precision_score(df_topic_vaccination_secondary.target, y_pred_Mnb_secondary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "72ed6baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        TRUE       1.00      0.02      0.04      1473\n",
      "       FALSE       0.02      1.00      0.04        27\n",
      "\n",
      "    accuracy                           0.04      1500\n",
      "   macro avg       0.51      0.51      0.04      1500\n",
      "weighted avg       0.98      0.04      0.04      1500\n",
      "\n",
      "[[  29 1444]\n",
      " [   0   27]]\n"
     ]
    }
   ],
   "source": [
    "df_topic_vaccination_target_names=[\"TRUE\",\"FALSE\"]\n",
    "print(metrics.classification_report(df_topic_vaccination_secondary.target, y_pred_Mnb_secondary,target_names=df_topic_vaccination_target_names))\n",
    "cm = metrics.confusion_matrix(df_topic_vaccination_secondary.target, y_pred_Mnb_secondary)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b234535",
   "metadata": {},
   "source": [
    "# using the secondary test data test with multinomial classifier we get an accuracy of 4 percent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1b7026",
   "metadata": {},
   "source": [
    "# Using the already fitted Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "84c13f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 6274)\n",
      "(1500, 6274)\n",
      "0.9826666666666667\n",
      "0.2777777777777778\n",
      "0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "df_X_rf_secondary = count_vect.transform(df_topic_vaccination_secondary['text'])\n",
    "print(df_X_rf_secondary.shape)\n",
    "df_X__rf_tfidf_secondary = tfidf_transformer.transform(df_X_rf_secondary)\n",
    "print(df_X__rf_tfidf_secondary.shape)\n",
    "# using trained nb classifer\n",
    "y_pred_rf_secondary= classifier_rf.predict(df_X__rf_tfidf_secondary)\n",
    "print(accuracy_score(df_topic_vaccination_secondary.target, y_pred_rf_secondary))\n",
    "print(f1_score(df_topic_vaccination_secondary.target, y_pred_rf_secondary))\n",
    "print(precision_score(df_topic_vaccination_secondary.target, y_pred_rf_secondary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "382bd721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        TRUE       0.99      1.00      0.99      1473\n",
      "       FALSE       0.56      0.19      0.28        27\n",
      "\n",
      "    accuracy                           0.98      1500\n",
      "   macro avg       0.77      0.59      0.63      1500\n",
      "weighted avg       0.98      0.98      0.98      1500\n",
      "\n",
      "[[1469    4]\n",
      " [  22    5]]\n"
     ]
    }
   ],
   "source": [
    "df_topic_vaccination_target_names=[\"TRUE\",\"FALSE\"]\n",
    "print(metrics.classification_report(df_topic_vaccination_secondary.target, y_pred_rf_secondary,target_names=df_topic_vaccination_target_names))\n",
    "cm = metrics.confusion_matrix(df_topic_vaccination_secondary.target, y_pred_rf_secondary)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcc517c",
   "metadata": {},
   "source": [
    "# using the secondary test data test with random classifier we get an accuracy of 98  percent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b4d2f5",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca68224",
   "metadata": {},
   "source": [
    "# Here feature extraction involves making use of regular expression, stop words, stemming, tokenization, n grams, word frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc8b191",
   "metadata": {},
   "source": [
    "# Feature engineering on primary data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "ab96db94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "813\n"
     ]
    }
   ],
   "source": [
    "def clean_text(df):\n",
    "    topic_vaccination = list()\n",
    "    lines = df_topic_vaccination[\"text\"].values.tolist()\n",
    "    for text in lines:\n",
    "        text = text.lower()\n",
    "        pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "        text = pattern.sub('', text)\n",
    "        text = re.sub(r\"[,.\\\"!@#$%^&*(){}?/;`~:<>+=-]\", \"\", text)\n",
    "        tokens = word_tokenize(text)\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        stripped = [w.translate(table) for w in tokens]\n",
    "        words = [word for word in stripped if word.isalpha()]\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        stop_words.discard(\"not\")\n",
    "        PS = PorterStemmer()\n",
    "        #lemmatizer = WordNetLemmatizer()\n",
    "        words = [PS.stem(w) for w in words if not w in stop_words]\n",
    "        #words = [lemmatizer.lemmatize(w) for w in words if not w in stop_words]\n",
    "        words = ' '.join(words)\n",
    "        topic_vaccination.append(words)\n",
    "        \n",
    "    return topic_vaccination\n",
    "\n",
    "clean_topic_vaccination_data_primary= clean_text(df_topic_vaccination.data)\n",
    "print(len(clean_topic_vaccination_data_primary))\n",
    "#display(df_topic_vaccination[\"text\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aa65f2",
   "metadata": {},
   "source": [
    "# sticking to stemming instead of lemmentisation as lemmentisation was treating vaccination, vaccinated, vaccines all uniquely.  stop words are used and where in 'not' is  discarded. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ee61a1",
   "metadata": {},
   "source": [
    "# extracting word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "be835a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vaccin</th>\n",
       "      <th>protect</th>\n",
       "      <th>safe</th>\n",
       "      <th>sick</th>\n",
       "      <th>motiv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>813 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     vaccin  protect  safe  sick  motiv\n",
       "0         1        0     0     0      0\n",
       "1         1        0     0     0      0\n",
       "2         0        0     0     0      0\n",
       "3         0        0     0     0      0\n",
       "4         1        0     0     0      0\n",
       "..      ...      ...   ...   ...    ...\n",
       "808       0        0     0     0      0\n",
       "809       2        0     0     0      0\n",
       "810       2        0     0     0      0\n",
       "811       0        0     0     0      0\n",
       "812       0        0     0     0      0\n",
       "\n",
       "[813 rows x 5 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = df_topic_vaccination[\"text\"].values.tolist()\n",
    "lst_words = [\"vaccin\", \"protect\", \"safe\",'sick','motiv']\n",
    "## count\n",
    "lst_grams = [len(word.split(\" \")) for word in lst_words]\n",
    "vectorizer = feature_extraction.text.CountVectorizer(vocabulary=lst_words, ngram_range=(min(lst_grams),max(lst_grams)))\n",
    "dict = {'Feature_Engineered_Text': clean_topic_vaccination_data_primary} \n",
    "fe_df = pd.DataFrame(dict)\n",
    "#fe_df\n",
    "dwf = pd.DataFrame(vectorizer.fit_transform(fe_df[\"Feature_Engineered_Text\"]).todense(), columns=lst_words)\n",
    "# ## add the new features as columns\n",
    "df_wf = pd.concat([fe_df, dwf.set_index(fe_df.index),df_topic_vaccination.target],axis=1)\n",
    "\n",
    "x=df_wf.iloc[:,1]+df_wf.iloc[:,2]+df_wf.iloc[:,3]+df_wf.iloc[:,4]+df_wf.iloc[:,5]\n",
    "df_wf.iloc[:,6:7]\n",
    "df_wf.iloc[:,1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c36918cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a49554",
   "metadata": {},
   "source": [
    "# Using Multinomial classifer on feature engineered primary data set without word frequency and n grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "f50025e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_X_train_primary,fe_X_test_primary, fe_y_train_primary, fe_y_test_primary=train_test_split(clean_topic_vaccination_data_primary, df_topic_vaccination.target, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "81d06ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method CountVectorizer.get_feature_names of CountVectorizer()>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(569, 3514)"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe_count_vect = CountVectorizer()\n",
    "feature_extraction_df_X_train_primary = fe_count_vect.fit_transform(fe_X_train_primary)\n",
    "print(fe_count_vect.get_feature_names)\n",
    "feature_extraction_df_X_train_primary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "c953381e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 3514)"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe_tfidf_transformer = TfidfTransformer()\n",
    "fe_df_X_train_tfidf_primary = fe_tfidf_transformer.fit_transform(feature_extraction_df_X_train_primary).toarray()\n",
    "fe_df_X_train_tfidf_primary.shape\n",
    "fe_df_X_train_tfidf_primary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "e30ab68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6557377049180327\n",
      "0.7801047120418848\n",
      "0.6422413793103449\n"
     ]
    }
   ],
   "source": [
    "fe_nb_model_primary = MultinomialNB(alpha=1.0).fit(fe_df_X_train_tfidf_primary, fe_y_train_primary)\n",
    "fe_X_test_primary_cv=fe_count_vect.transform(fe_X_test_primary)\n",
    "fe_X_test_primary_tf=fe_tfidf_transformer.transform(fe_X_test_primary_cv)\n",
    "fe_y_pred_Mnb_primary = fe_nb_model_primary.predict(fe_X_test_primary_tf)\n",
    "print(accuracy_score(fe_y_test_primary, fe_y_pred_Mnb_primary))\n",
    "print(f1_score(fe_y_test_primary, fe_y_pred_Mnb_primary))\n",
    "print(precision_score(fe_y_test_primary, fe_y_pred_Mnb_primary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "51b5d021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        TRUE       0.92      0.12      0.21        94\n",
      "       FALSE       0.64      0.99      0.78       150\n",
      "\n",
      "    accuracy                           0.66       244\n",
      "   macro avg       0.78      0.56      0.49       244\n",
      "weighted avg       0.75      0.66      0.56       244\n",
      "\n",
      "[[ 11  83]\n",
      " [  1 149]]\n"
     ]
    }
   ],
   "source": [
    "df_topic_vaccination_target_names=[\"TRUE\",\"FALSE\"]\n",
    "print(metrics.classification_report(fe_y_test_primary, fe_y_pred_Mnb_primary,target_names=df_topic_vaccination_target_names))\n",
    "cm = metrics.confusion_matrix(fe_y_test_primary,fe_y_pred_Mnb_primary)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60103e75",
   "metadata": {},
   "source": [
    "# Using Multinomial classifer on feature engineered word frequency primary data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "453f853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_X_train_primary,wf_X_test_primary, wf_y_train_primary, wf_y_test_primary = train_test_split(df_wf.iloc[:,1:6],df_wf.iloc[:,6], test_size = 0.3, random_state =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "3b53ff49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#taking transformed tf of primary train set(count vectorised text data)\n",
    "fe_df_X_train_tfidf_primary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "12023feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [2, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word frequency columns of primary training data set \n",
    "wf_train_primary=wf_X_train_primary.to_numpy()\n",
    "wf_train_primary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "229068f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 3519)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatinating the primary data\n",
    "wf_df_X_train_primary=pd.DataFrame(np.concatenate((fe_df_X_train_tfidf_primary,wf_train_primary),axis=1))\n",
    "wf_df_X_train_primary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "38861c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244, 3514)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#taking transformed tf of primary test set(count vectorised text data)\n",
    "fe_X_test_primary_tf_array=fe_X_test_primary_tf.toarray()\n",
    "fe_X_test_primary_tf_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "c3c6584b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244, 5)"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##word frequency columns of primary test data set \n",
    "wf_X_test_primary_array=wf_X_test_primary.to_numpy()\n",
    "wf_X_test_primary_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "8588c757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244, 3519)"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wf_df_X_test_primary=pd.DataFrame(np.concatenate((fe_X_test_primary_tf_array,wf_X_test_primary_array),axis=1))\n",
    "#wf_df_X_test_primary=np.concatenate((v,wf_test_primary), axis=0)\n",
    "wf_df_X_test_primary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "3ed167b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7827868852459017\n",
      "0.848137535816619\n",
      "0.7437185929648241\n"
     ]
    }
   ],
   "source": [
    "wf_nb_model_primary = MultinomialNB(alpha=1.0).fit(wf_df_X_train_primary,wf_y_train_primary)\n",
    "wf_y_pred_Mnb_primary = wf_nb_model_primary.predict(wf_df_X_test_primary)\n",
    "print(accuracy_score(wf_y_test_primary, wf_y_pred_Mnb_primary))\n",
    "print(f1_score(wf_y_test_primary, wf_y_pred_Mnb_primary))\n",
    "print(precision_score(wf_y_test_primary,wf_y_pred_Mnb_primary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bc5471",
   "metadata": {},
   "source": [
    "# Therefore by applying word frequency and n grams, 78 percent of accuracy was achievable which increased from before which was 61 percent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e24845f",
   "metadata": {},
   "source": [
    "# Using Random forest classifier on featured engineered primary data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "d0ec7a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9098360655737705\n",
      "0.9276315789473684\n",
      "0.9155844155844156\n"
     ]
    }
   ],
   "source": [
    "fe_classifier_rf = RandomForestClassifier(n_estimators=100)\n",
    "fe_classifier_rf.fit(fe_df_X_train_tfidf_primary,fe_y_train_primary)\n",
    "fe_y_pred_rf_primary=fe_classifier_rf.predict(fe_X_test_primary_tf)\n",
    "print(accuracy_score(fe_y_test_primary,fe_y_pred_rf_primary))\n",
    "print(f1_score(fe_y_test_primary, fe_y_pred_rf_primary))\n",
    "print(precision_score(fe_y_test_primary,fe_y_pred_rf_primary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "6c65233d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        TRUE       0.90      0.86      0.88        94\n",
      "       FALSE       0.92      0.94      0.93       150\n",
      "\n",
      "    accuracy                           0.91       244\n",
      "   macro avg       0.91      0.90      0.90       244\n",
      "weighted avg       0.91      0.91      0.91       244\n",
      "\n",
      "[[ 81  13]\n",
      " [  9 141]]\n"
     ]
    }
   ],
   "source": [
    "df_topic_vaccination_target_names=[\"TRUE\",\"FALSE\"]\n",
    "print(metrics.classification_report(fe_y_test_primary, fe_y_pred_rf_primary,target_names=df_topic_vaccination_target_names))\n",
    "cm = metrics.confusion_matrix(fe_y_test_primary,fe_y_pred_rf_primary)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5a643c",
   "metadata": {},
   "source": [
    "# With random forest classifier, we get 87 percentage of accurage on primary test(0.3) data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31046181",
   "metadata": {},
   "source": [
    "# Using Random forest classifer on feature engineered word frequency primary data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "13931aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9180327868852459\n",
      "0.9324324324324323\n",
      "0.9452054794520548\n"
     ]
    }
   ],
   "source": [
    "fe_classifier_rf_wf = RandomForestClassifier(n_estimators=100)\n",
    "fe_classifier_rf_wf.fit(wf_df_X_train_primary,wf_y_train_primary)\n",
    "fe_y_pred_rf_primary_wf=fe_classifier_rf_wf.predict(wf_df_X_test_primary)\n",
    "print(accuracy_score(fe_y_test_primary,fe_y_pred_rf_primary_wf))\n",
    "print(f1_score(fe_y_test_primary, fe_y_pred_rf_primary_wf))\n",
    "print(precision_score(fe_y_test_primary,fe_y_pred_rf_primary_wf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "c6a022df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        TRUE       0.88      0.91      0.90        94\n",
      "       FALSE       0.95      0.92      0.93       150\n",
      "\n",
      "    accuracy                           0.92       244\n",
      "   macro avg       0.91      0.92      0.91       244\n",
      "weighted avg       0.92      0.92      0.92       244\n",
      "\n",
      "[[ 81  13]\n",
      " [  9 141]]\n"
     ]
    }
   ],
   "source": [
    "df_topic_vaccination_target_names=[\"TRUE\",\"FALSE\"]\n",
    "print(metrics.classification_report(fe_y_test_primary, fe_y_pred_rf_primary_wf,target_names=df_topic_vaccination_target_names))\n",
    "cm = metrics.confusion_matrix(fe_y_test_primary,fe_y_pred_rf_primary)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9d7f95",
   "metadata": {},
   "source": [
    "# after applying above feature extraction on the primary data set for random classification model, the accuarcy increased from 91 percent to 92 percent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504400c8",
   "metadata": {},
   "source": [
    "# Feature engineering on secondary test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "510ee320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['award',\n",
       " 'cancel school year sol',\n",
       " '',\n",
       " 'protect nurs',\n",
       " 'senseless imprison mom first time offend nonviol crime',\n",
       " 'demand immedi releas incarcer knox counti jail',\n",
       " 'petit recal desmond elliot lago hous assembl suruler constitu',\n",
       " 'texa uil spring sportscompetit complet summer',\n",
       " 'priorit vaccin florida teacher',\n",
       " 'save plum island coffe roaster',\n",
       " 'suspend rent mortgag canada',\n",
       " 'ask citi winstonsalem support instreet dine downtown restur',\n",
       " 'onlin class close physic bmcc campu due outbreak',\n",
       " 'appello per la pace etiopia',\n",
       " 'stop guinea pig vaccin test africa covid corona viru',\n",
       " 'rowan univers univers pass system',\n",
       " 'allow athlet therapist treat patient',\n",
       " 'allow not covid relat evict',\n",
       " 'freeneko navajo counti jail',\n",
       " 'özel okul']"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(df):\n",
    "    topic_vaccination_secondary = list()\n",
    "    lines = df.values.tolist()\n",
    "    for text in lines:\n",
    "        text = text.lower()\n",
    "        pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "        text = pattern.sub('', text)\n",
    "        text = re.sub(r\"[,.\\\"!@#$%^&*(){}?/;`~:<>+=-]\", \"\", text)\n",
    "        tokens = word_tokenize(text)\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        stripped = [w.translate(table) for w in tokens]\n",
    "        words = [word for word in stripped if word.isalpha()]\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        stop_words.discard(\"not\")\n",
    "        PS = PorterStemmer()\n",
    "        #lemmatizer = WordNetLemmatizer()\n",
    "        words = [PS.stem(w) for w in words if not w in stop_words]\n",
    "        #words = [lemmatizer.lemmatize(w) for w in words if not w in stop_words]\n",
    "        words = ' '.join(words)\n",
    "        topic_vaccination_secondary.append(words)\n",
    "    return topic_vaccination_secondary\n",
    "\n",
    "clean_topic_vaccination_data_secondary= clean_text(df_topic_vaccination_secondary.data)\n",
    "clean_topic_vaccination_data_secondary[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae24a7f",
   "metadata": {},
   "source": [
    "# Using the already fitted Multinomial classifier's model on featured secondary dataset.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "1e6baf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the word frequency method for secondary entire test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "f723fcfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_Engineered_Text_secondary</th>\n",
       "      <th>vaccin</th>\n",
       "      <th>protect</th>\n",
       "      <th>safe</th>\n",
       "      <th>sick</th>\n",
       "      <th>motiv</th>\n",
       "      <th>final_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>award</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cancel school year sol</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>protect nurs</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>senseless imprison mom first time offend nonvi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>null void premier leagu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>free public transport nh staff accompani pay rise</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>pm pleas give immedi covid insur cover nh staff</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>say osha propos perman rule</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>ntu view result decid su</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Feature_Engineered_Text_secondary  vaccin  protect  \\\n",
       "0                                                 award       0        0   \n",
       "1                                cancel school year sol       0        0   \n",
       "2                                                             0        0   \n",
       "3                                          protect nurs       0        1   \n",
       "4     senseless imprison mom first time offend nonvi...       0        0   \n",
       "...                                                 ...     ...      ...   \n",
       "1495                            null void premier leagu       0        0   \n",
       "1496  free public transport nh staff accompani pay rise       0        0   \n",
       "1497    pm pleas give immedi covid insur cover nh staff       0        0   \n",
       "1498                        say osha propos perman rule       0        0   \n",
       "1499                           ntu view result decid su       0        0   \n",
       "\n",
       "      safe  sick  motiv  final_label  \n",
       "0        0     0      0        False  \n",
       "1        0     0      0        False  \n",
       "2        0     0      0        False  \n",
       "3        0     0      0        False  \n",
       "4        0     0      0        False  \n",
       "...    ...   ...    ...          ...  \n",
       "1495     0     0      0        False  \n",
       "1496     0     0      0        False  \n",
       "1497     0     0      0        False  \n",
       "1498     0     0      0        False  \n",
       "1499     0     0      0        False  \n",
       "\n",
       "[1500 rows x 7 columns]"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = df_topic_vaccination_secondary[\"text\"].values.tolist()\n",
    "lst_words = [\"vaccin\", \"protect\", \"safe\",'sick','motiv']\n",
    "## count\n",
    "lst_grams = [len(word.split(\" \")) for word in lst_words]\n",
    "vectorizer = feature_extraction.text.CountVectorizer(vocabulary=lst_words, ngram_range=(min(lst_grams),max(lst_grams)))\n",
    "dict_secondary = {'Feature_Engineered_Text_secondary': clean_topic_vaccination_data_secondary} \n",
    "fe_df = pd.DataFrame(dict_secondary)\n",
    "dwf_second = pd.DataFrame(vectorizer.fit_transform(fe_df[\"Feature_Engineered_Text_secondary\"]).todense(), columns=lst_words)\n",
    "# ## add the new features as columns\n",
    "df_wf_second = pd.concat([fe_df,dwf_second.set_index(fe_df.index),df_topic_vaccination_secondary.target],axis=1)\n",
    "df_wf_second\n",
    "# x=df_wf.iloc[:,1]+df_wf_second.iloc[:,2]+df_wf.iloc[:,3]+df_wf.iloc[:,4]+df_wf.iloc[:,5]\n",
    "# df_wf.iloc[:,6:7]\n",
    "# df_wf.iloc[:,1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "b9b500d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_Engineered_Text_secondary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>award</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cancel school year sol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>protect nurs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>senseless imprison mom first time offend nonvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>null void premier leagu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>free public transport nh staff accompani pay rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>pm pleas give immedi covid insur cover nh staff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>say osha propos perman rule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>ntu view result decid su</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Feature_Engineered_Text_secondary\n",
       "0                                                 award\n",
       "1                                cancel school year sol\n",
       "2                                                      \n",
       "3                                          protect nurs\n",
       "4     senseless imprison mom first time offend nonvi...\n",
       "...                                                 ...\n",
       "1495                            null void premier leagu\n",
       "1496  free public transport nh staff accompani pay rise\n",
       "1497    pm pleas give immedi covid insur cover nh staff\n",
       "1498                        say osha propos perman rule\n",
       "1499                           ntu view result decid su\n",
       "\n",
       "[1500 rows x 1 columns]"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wf_second.iloc[:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "73ab2ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 3514)"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count vectorising the text data of secondary entire data set\n",
    "fe_count_vect_second=fe_count_vect.transform(clean_topic_vaccination_data_secondary)\n",
    "fe_tfidf_transformer_second=fe_tfidf_transformer.transform(fe_count_vect_second)\n",
    "fe_tfidf_transformer_second_array=fe_tfidf_transformer_second.toarray()\n",
    "fe_tfidf_transformer_second_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3e85a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking the word frequency into consideration.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "434be964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 5)"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wf__second_array=df_wf_second.iloc[:,1:6].to_numpy()\n",
    "wf__second_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "d0b1af3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 3519)"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatinating the secondary data for Multinaives bayes prediction..\n",
    "wf_df_X_test_secondary=pd.DataFrame(np.concatenate((fe_tfidf_transformer_second_array,wf__second_array),axis=1))\n",
    "wf_df_X_test_secondary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "8ea59423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.306\n",
      "0.04931506849315069\n",
      "0.025280898876404494\n"
     ]
    }
   ],
   "source": [
    "#using trained nb classifer of featured engineer..\n",
    "fe_y_pred_Mnb_secondary= wf_nb_model_primary.predict(wf_df_X_test_secondary)\n",
    "print(accuracy_score(df_topic_vaccination_secondary.target, fe_y_pred_Mnb_secondary))\n",
    "print(f1_score(df_topic_vaccination_secondary.target, fe_y_pred_Mnb_secondary))\n",
    "print(precision_score(df_topic_vaccination_secondary.target,fe_y_pred_Mnb_secondary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "df33e495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        TRUE       1.00      0.29      0.45      1473\n",
      "       FALSE       0.03      1.00      0.05        27\n",
      "\n",
      "    accuracy                           0.31      1500\n",
      "   macro avg       0.51      0.65      0.25      1500\n",
      "weighted avg       0.98      0.31      0.45      1500\n",
      "\n",
      "[[ 432 1041]\n",
      " [   0   27]]\n"
     ]
    }
   ],
   "source": [
    "df_topic_vaccination_target_names=[\"TRUE\",\"FALSE\"]\n",
    "print(metrics.classification_report(df_topic_vaccination_secondary.target, fe_y_pred_Mnb_secondary,target_names=df_topic_vaccination_target_names))\n",
    "cm = metrics.confusion_matrix(df_topic_vaccination_secondary.target, fe_y_pred_Mnb_secondary)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f78448",
   "metadata": {},
   "source": [
    "# The accuracy for the model is 31 percent.which has increased from 4 percent of secondary data set without feature extraction.This confirms the increase in the accuracy after feature extraction for multinomial bayes secondary test data set "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bd1753",
   "metadata": {},
   "source": [
    "# Using the already fitted Random Forest Classifier model on featured secondary data set.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "749a4981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9933333333333333\n",
      "0.782608695652174\n",
      "0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# using trained random forest classifier....\n",
    "fe_y_pred_rf_secondary= fe_classifier_rf_wf.predict(wf_df_X_test_secondary)\n",
    "print(accuracy_score(df_topic_vaccination_secondary.target, fe_y_pred_rf_secondary))\n",
    "print(f1_score(df_topic_vaccination_secondary.target, fe_y_pred_rf_secondary))\n",
    "print(precision_score(df_topic_vaccination_secondary.target, fe_y_pred_rf_secondary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "06302188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        TRUE       0.99      0.99      0.99      1473\n",
      "       FALSE       0.58      0.67      0.62        27\n",
      "\n",
      "    accuracy                           0.99      1500\n",
      "   macro avg       0.79      0.83      0.81      1500\n",
      "weighted avg       0.99      0.99      0.99      1500\n",
      "\n",
      "[[1460   13]\n",
      " [   9   18]]\n"
     ]
    }
   ],
   "source": [
    "df_topic_vaccination_target_names=[\"TRUE\",\"FALSE\"]\n",
    "print(metrics.classification_report(df_topic_vaccination_secondary.target, fe_y_pred_rf_secondary,target_names=df_topic_vaccination_target_names))\n",
    "cm = metrics.confusion_matrix(df_topic_vaccination_secondary.target, fe_y_pred_rf_secondary)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b72bc6a",
   "metadata": {},
   "source": [
    "# The accuracy for the model is 99 percent.which has increased from 98 percent of secondary data set without feature extraction.This confirms the increase in the accuracy after feature extraction for random forest secondary test data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154cd4a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
